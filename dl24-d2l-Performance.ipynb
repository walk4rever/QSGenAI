{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8556956c",
      "metadata": {
        "id": "8556956c"
      },
      "source": [
        "# Chapter 13. Computational Performance\n",
        "\n",
        "* This chapter will focus on the major factors that affect computational performance: imperative programming, symbolic programming, asynchronous computing, automatic parallelism, and multi-GPU computation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe71ac0f",
      "metadata": {
        "id": "fe71ac0f"
      },
      "source": [
        "## Chapter 13.1 Compilers and Interpreters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9641412b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9641412b",
        "outputId": "2242d029-b842-4e2d-cc94-848d8911ae2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ],
      "source": [
        "def add(a, b):\n",
        "    return a + b\n",
        "\n",
        "def fancy_func(a, b, c, d):\n",
        "    e = add(a, b)\n",
        "    f = add(c, d)\n",
        "    g = add(e, f)\n",
        "\n",
        "    return g\n",
        "\n",
        "print(fancy_func(1, 2, 3, 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e6964dc0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6964dc0",
        "outputId": "2acbb8bb-52fc-4de4-d582-8f6779d08344"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0410, 0.2545]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l\n",
        "\n",
        "# Factory for networks\n",
        "def get_net():\n",
        "    net = nn.Sequential(nn.Linear(512, 256),\n",
        "                       nn.ReLU(),\n",
        "                       nn.Linear(256, 128),\n",
        "                       nn.ReLU(),\n",
        "                       nn.Linear(128, 2))\n",
        "    return net\n",
        "\n",
        "x = torch.randn(size=(1, 512))\n",
        "net = get_net()\n",
        "net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3e6ffe0d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e6ffe0d",
        "outputId": "27c4fbb8-4f02-469e-aeca-840d181c3424"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0410, 0.2545]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# By converting the model using torch.jit.script function,\n",
        "# we are able to compile and optimize the computation in the MLP.\n",
        "\n",
        "net = torch.jit.script(net)\n",
        "net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0334bd6d",
      "metadata": {
        "id": "0334bd6d"
      },
      "outputs": [],
      "source": [
        "# Benchmark to compare with or without jitscript\n",
        "\n",
        "class Benchmark:\n",
        "    \"\"\"For measuring running time.\"\"\"\n",
        "\n",
        "    def __init__(self, description='Done'):\n",
        "        self.description = description\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.timer = d2l.Timer()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, *args):\n",
        "        print(f'{self.description}: {self.timer.stop():.4f} sec')\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a0ab2644",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0ab2644",
        "outputId": "a0989a90-7cec-4821-dfc6-733b1c0fd5bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without torchscript: 0.2719 sec\n",
            "With torchscript: 0.2697 sec\n"
          ]
        }
      ],
      "source": [
        "net = get_net()\n",
        "\n",
        "with Benchmark('Without torchscript'):\n",
        "    for i in range(3000):\n",
        "        net(x)\n",
        "\n",
        "net = torch.jit.script(net)\n",
        "\n",
        "with Benchmark('With torchscript'):\n",
        "    for i in range(3000):\n",
        "        net(x)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be2ab9f9",
      "metadata": {
        "id": "be2ab9f9",
        "outputId": "2a9c0ed8-55f9-4cd6-8209-6e710aba28c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-r--r--  1 yfzhu  staff   651K Jan 29 11:47 my_mlp\r\n"
          ]
        }
      ],
      "source": [
        "net.save('my_mlp')\n",
        "!ls -lh my_mlp*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95eee2b0",
      "metadata": {
        "id": "95eee2b0"
      },
      "source": [
        "## Chapter 13.2 Asynchronous Computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa13e9ae",
      "metadata": {
        "id": "aa13e9ae"
      },
      "outputs": [],
      "source": [
        "# Installation of d2l packages\n",
        "\n",
        "!pip install torch==2.0.0 torchvision==0.15.1\n",
        "!pip install d2l==1.0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "84668dcc",
      "metadata": {
        "id": "84668dcc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import numpy\n",
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "74f4f88b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74f4f88b",
        "outputId": "cdea75e0-0fa0-4ea3-8f46-2e6705b9f1e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy: 1.4007 sec\n",
            "torch: 0.0085 sec\n"
          ]
        }
      ],
      "source": [
        "# Warmup for GPU computation\n",
        "device = d2l.try_gpu()\n",
        "a = torch.randn(size=(1000, 1000), device=device)\n",
        "b = torch.mm(a, a)\n",
        "\n",
        "with d2l.Benchmark('numpy'):\n",
        "    for _ in range(10):\n",
        "        a = numpy.random.normal(size=(1000, 1000))\n",
        "        b = numpy.dot(a, a)\n",
        "\n",
        "with d2l.Benchmark('torch'):\n",
        "    for _ in range(10):\n",
        "        a = torch.randn(size=(1000, 1000), device=device)\n",
        "        b = torch.mm(a, a)\n",
        "    torch.cuda.synchronize(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d400ea30",
      "metadata": {
        "id": "d400ea30"
      },
      "outputs": [],
      "source": [
        "# test for saving to github"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}