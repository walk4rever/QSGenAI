{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d0772cf",
   "metadata": {},
   "source": [
    "## Chapter 6 Builder's Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa45b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa95dce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.LazyLinear(256), nn.ReLU(), nn.LazyLinear(10))\n",
    "X = torch.rand(2, 20)\n",
    "net(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6d06000",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.LazyLinear(256)\n",
    "        self.out = nn.LazyLinear(10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.out(F.relu(self.hidden(X)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643c8ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MLP()\n",
    "X = torch.rand(4, 30)\n",
    "net(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cc4e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define my own version Sequentical\n",
    "\n",
    "class MySequential(nn.Module):\n",
    "    \n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args):\n",
    "            self.add_module(str(idx), module)\n",
    "            \n",
    "    \n",
    "    def forward(self, X):\n",
    "        for module in self.children():\n",
    "            X = module(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49ad42bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MySequential(nn.LazyLinear(256), nn.ReLU(), nn.LazyLinear(10))\n",
    "net(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3990f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define FixedHiddenMLP\n",
    "\n",
    "class FixedHiddenMLP(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rand_weight = torch.rand((30, 20))\n",
    "        self.linear = nn.LazyLinear(20)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.linear(X)\n",
    "        X = F.relu(X @ self.rand_weight + 1)\n",
    "        \n",
    "        X = self.linear(X)\n",
    "        \n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        \n",
    "        return X.sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c12d79b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (4x20 and 30x20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m net \u001b[38;5;241m=\u001b[39m FixedHiddenMLP()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[22], line 13\u001b[0m, in \u001b[0;36mFixedHiddenMLP.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m     12\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(X)\n\u001b[0;32m---> 13\u001b[0m     X \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand_weight\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(X)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m X\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4x20 and 30x20)"
     ]
    }
   ],
   "source": [
    "net = FixedHiddenMLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14c055f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.LazyLinear(64), nn.ReLU(),\n",
    "                                nn.LazyLinear(32), nn.ReLU())\n",
    "        self.linear = nn.LazyLinear(16)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.linear(self.net(X))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7daa42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5163e-01, -2.2268e-01, -1.3237e-01, -2.6621e-01, -1.1483e-04,\n",
       "          2.3322e-01, -1.9979e-02,  2.0555e-01,  1.2910e-01,  7.8092e-02,\n",
       "          3.2890e-01,  1.0668e-01,  8.7630e-02, -1.8570e-01,  1.0008e-01,\n",
       "          1.2530e-01,  1.1027e-01,  2.1349e-01,  1.0495e-01,  1.4753e-01],\n",
       "        [-2.7562e-01, -2.3336e-01, -1.2803e-01, -2.4663e-01,  7.9789e-03,\n",
       "          2.4696e-01, -2.5395e-02,  1.7698e-01,  1.2999e-01,  9.8150e-02,\n",
       "          3.3663e-01,  1.1383e-01,  6.8412e-02, -2.2596e-01,  1.2068e-01,\n",
       "          1.3152e-01,  7.6674e-02,  2.2618e-01,  7.1008e-02,  1.6124e-01],\n",
       "        [-2.4077e-01, -2.1682e-01, -1.5097e-01, -2.6622e-01,  1.1464e-02,\n",
       "          2.8073e-01, -5.9976e-02,  2.1258e-01,  8.9256e-02,  6.7808e-02,\n",
       "          3.4041e-01,  9.3593e-02,  1.0705e-01, -1.9967e-01,  9.5986e-02,\n",
       "          1.3439e-01,  1.0999e-01,  2.0902e-01,  1.2148e-01,  1.6793e-01],\n",
       "        [-2.7319e-01, -2.3678e-01, -1.1238e-01, -2.4536e-01,  1.2746e-04,\n",
       "          2.5838e-01, -3.8424e-02,  2.0181e-01,  1.3875e-01,  1.0593e-01,\n",
       "          3.3338e-01,  9.9263e-02,  8.4419e-02, -2.3442e-01,  1.2344e-01,\n",
       "          1.3738e-01,  8.3649e-02,  2.0000e-01,  9.8835e-02,  1.4959e-01]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chimera = nn.Sequential(NestMLP(), nn.LazyLinear(20))\n",
    "chimera(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "012e30fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try the paramter management\n",
    "\n",
    "net = nn.Sequential(nn.LazyLinear(8), nn.ReLU(), nn.LazyLinear(24), nn.ReLU(), nn.LazyLinear(1))\n",
    "\n",
    "X = torch.rand(size=(2, 4))\n",
    "\n",
    "net(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eae60db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.0692,  0.1466,  0.1105, -0.0545,  0.0843,  0.1547, -0.0919,  0.1267,\n",
       "                       -0.0845, -0.1510,  0.1591,  0.1269,  0.0244,  0.0706,  0.1843, -0.0009,\n",
       "                        0.0536,  0.1240, -0.1626,  0.1561,  0.1958, -0.0400, -0.0165, -0.0105]])),\n",
       "             ('bias', tensor([-0.1214]))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[4].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b26f332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0.weight', torch.Size([8, 4])),\n",
       " ('0.bias', torch.Size([8])),\n",
       " ('2.weight', torch.Size([24, 8])),\n",
       " ('2.bias', torch.Size([24])),\n",
       " ('4.weight', torch.Size([1, 24])),\n",
       " ('4.bias', torch.Size([1]))]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(name, param.shape) for name, param in net.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e6be7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "# Shared Layer\n",
    "\n",
    "shared = nn.LazyLinear(8)\n",
    "\n",
    "net = nn.Sequential(nn.LazyLinear(8), nn.ReLU(), \n",
    "                    shared, nn.ReLU(), \n",
    "                    shared, nn.ReLU(), \n",
    "                    nn.LazyLinear(1))\n",
    "\n",
    "net(X)\n",
    "\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
    "\n",
    "net[2].weight.data[0, 0] = 100\n",
    "\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36abf9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to initialize the parameters\n",
    "\n",
    "net = nn.Sequential(nn.LazyLinear(8), nn.ReLU(),\n",
    "                nn.LazyLinear(1))\n",
    "\n",
    "X = torch.rand(size=(100, 4))\n",
    "\n",
    "net(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f26f85cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 0.0068, -0.0014,  0.0037, -0.0002,  0.0206, -0.0163,  0.0103, -0.0114]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.], requires_grad=True))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize all weight parameters as Gaussian random\n",
    "\n",
    "def init_normal(module):\n",
    "    if type(module) == nn.Linear:\n",
    "        nn.init.normal_(module.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(module.bias)\n",
    "        \n",
    "net.apply(init_normal)\n",
    "\n",
    "net[2].weight, net[2].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a6991f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_xavier(module):\n",
    "    if type(module) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "        \n",
    "def init_42(module):\n",
    "    if type(module) == nn.Linear:\n",
    "        nn.init.constant_(module.weight, 42)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7a9584da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4842,  0.2634,  0.2337, -0.5954])\n",
      "tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n"
     ]
    }
   ],
   "source": [
    "net[0].apply(init_xavier)\n",
    "net[2].apply(init_42)\n",
    "\n",
    "print(net[0].weight.data[0])\n",
    "print(net[2].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27e0da66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init weight torch.Size([8, 4])\n",
      "Init weight torch.Size([1, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-5.6492, -9.6307, -0.0000, -5.0267],\n",
       "        [-0.0000,  9.0222, -0.0000,  0.0000]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_init(module):\n",
    "    if type(module) == nn.Linear:\n",
    "        print(\"Init\", *[(name, param.shape)\n",
    "                        for name, param in module.named_parameters()][0])\n",
    "        nn.init.uniform_(module.weight, -10, 10)\n",
    "        module.weight.data *= module.weight.data.abs() >= 5\n",
    "\n",
    "net.apply(my_init)\n",
    "net[0].weight[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6829c4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42.0000, -8.6307,  1.0000, -4.0267])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data[:] += 1\n",
    "net[0].weight.data[0, 0] = 42\n",
    "net[0].weight.data[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef46f37b",
   "metadata": {},
   "source": [
    "* Chapter 6.5 Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d8e6afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9a7f3237",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return X - X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7dcf3dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = CenteredLayer()\n",
    "layer(torch.tensor([1.0, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e61fa129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0245e-08, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.LazyLinear(128), CenteredLayer())\n",
    "\n",
    "Y = net(torch.rand(4, 8))\n",
    "\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e39eef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer with parameters\n",
    "\n",
    "class MyLinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1be625e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2311, -1.0672,  0.9563],\n",
       "        [-0.3222, -0.7091,  3.1810],\n",
       "        [-0.2466,  0.2823,  1.1680],\n",
       "        [-0.3492, -0.9549, -0.4932],\n",
       "        [-0.4948,  0.8325, -1.7294]], requires_grad=True)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = MyLinear(5, 3)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6444b4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 2.0850],\n",
       "        [0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(torch.rand(2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a8575835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7982],\n",
       "        [2.9903]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
    "net(torch.rand(2, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd6bfd9",
   "metadata": {},
   "source": [
    "* Chapter 6.6 File I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a46eaa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and saving tensors\n",
    "\n",
    "x = torch.arange(4)\n",
    "torch.save(x, '../data/x-file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d8833eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.load('../data/x-file')\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f0e12197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros(4)\n",
    "torch.save([x, y], '../data/x-file')\n",
    "\n",
    "x2, y2 = torch.load('../data/x-file')\n",
    "\n",
    "x2,y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e9dd6a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x': x, 'y':y}\n",
    "torch.save(mydict, '../data/mydict')\n",
    "\n",
    "mydict2 = torch.load('../data/mydict')\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b8b3ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and save model parameters\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.LazyLinear(256)\n",
    "        self.output = nn.LazyLinear(10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.output(F.relu(self.hidden(X)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "672ca460",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MLP()\n",
    "\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4a5faebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), '../data/mlp.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d3155b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): LazyLinear(in_features=0, out_features=256, bias=True)\n",
       "  (output): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "\n",
    "clone.load_state_dict(torch.load('../data/mlp.params'))\n",
    "\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "73fb332e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174f0654",
   "metadata": {},
   "source": [
    "* Chapter 6.7 GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "df3b697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "838a8c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'),\n",
       " device(type='cuda', index=0),\n",
       " device(type='cuda', index=2))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cpu():\n",
    "    return torch.device('cpu')\n",
    "\n",
    "def gpu(i=0):\n",
    "    return torch.device(f'cuda:{i}')\n",
    "\n",
    "cpu(), gpu(), gpu(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "48dddcbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def num_gpus():\n",
    "    return torch.cuda.device_count()\n",
    "\n",
    "num_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8ea59afb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtry_all_gpus\u001b[39m():\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [gpu[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_gpus())]\n\u001b[0;32m----> 9\u001b[0m try_gpu(), try_gpu(\u001b[38;5;241m10\u001b[39m), \u001b[43mtry_all_gpus\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[91], line 7\u001b[0m, in \u001b[0;36mtry_all_gpus\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtry_all_gpus\u001b[39m():\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [gpu[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_gpus())]\n",
      "Cell \u001b[0;32mIn[91], line 7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtry_all_gpus\u001b[39m():\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mgpu\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_gpus())]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'function' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def try_gpu(i=0):\n",
    "    if num_gpus() >= i + 1:\n",
    "        return gpu(i)\n",
    "    return cpu()\n",
    "\n",
    "def try_all_gpus():\n",
    "    return [gpu[i] for i in range(num_gpus())]\n",
    "\n",
    "try_gpu(), try_gpu(10), try_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9864106a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "249e5a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones(2, 3, device=try_gpu())\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ef01991b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1497, 0.5114, 0.1653],\n",
       "        [0.6972, 0.9573, 0.7402]], device='cuda:0')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.rand(2, 3, device=try_gpu(0))\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a6d438c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN on GPU\n",
    "\n",
    "net = nn.Sequential(nn.LazyLinear(1))\n",
    "net = net.to(device=try_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7d983658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4935],\n",
       "        [-0.4935]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "40eb83e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6acd7148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda', index=0),\n",
       " device(type='cpu'),\n",
       " [device(type='cuda', index=0)])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_gpu(i=0):  #@save\n",
    "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "def try_all_gpus():  #@save\n",
    "    \"\"\"返回所有可用的GPU，如果没有GPU，则返回[cpu(),]\"\"\"\n",
    "    devices = [torch.device(f'cuda:{i}')\n",
    "             for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]\n",
    "\n",
    "try_gpu(), try_gpu(10), try_all_gpus()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
